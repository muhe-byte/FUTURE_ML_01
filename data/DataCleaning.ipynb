{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b10e736-660a-420d-824a-e22e7e54bdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete!\n",
      "Dataset range: 2014-01-01 00:00:00 to 2016-07-31 00:00:00\n",
      "        Date  Sales  Stock  Price\n",
      "0 2014-01-01      0   4972   1.29\n",
      "1 2014-01-02     70   4902   1.29\n",
      "2 2014-01-03     59   4843   1.29\n",
      "3 2014-01-04     93   4750   1.29\n",
      "4 2014-01-05     96   4654   1.29\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "           ======================================================\n",
    "           =                DATA CLEANING                       =\n",
    "           ======================================================\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "# Importing the dataset \n",
    "df = pd.read_csv('/workspaces/FUTURE_ML_01/data/mock_kaggle.csv')\n",
    "\n",
    "# the data column change to English for understanding these are the original portuguese headers of the data set\n",
    "# which the translations makes analysis easier\n",
    "df = df.rename(columns={\n",
    "    'data':'Date',\n",
    "    'venda':'Sales',\n",
    "    'estoque':'Stock',\n",
    "    'preco':'Price'\n",
    "})\n",
    "\n",
    "# making the date proper date time objects allows python to understand months, years and seasons \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the data by Date\n",
    "# Time-series models require data to be in chronological order\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Daily Aggregation. It is used to transform \"transactional data\" (multiple rows per day) into \"time-series data\" (one single row per day).\n",
    "# Machine Learning models for forecasting (like Prophet or ARIMA) require a consistent timeline. \n",
    "# They need to see exactly one data point per day to understand the trend correctly.\n",
    "# If there are multiple entries for the same day, we sum them up\n",
    "df_cleaned = df.groupby('Date').agg({\n",
    "    'Sales': 'sum',\n",
    "    'Stock': 'last', # Take the stock level at the end of the day\n",
    "    'Price': 'mean'  # Take the average price for that day\n",
    "}).reset_index()\n",
    "\n",
    "# 6. Save the cleaned data to a new file\n",
    "df_cleaned.to_csv('cleaned_retail_data.csv', index=False)\n",
    "print(\"Data cleaning complete!\")\n",
    "print(f\"Dataset range: {df_cleaned['Date'].min()} to {df_cleaned['Date'].max()}\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92a625-d769-423e-bd31-e55a76e7f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                 ======================================================\n",
    "                 =          EDA & VISUALIZATION                       =\n",
    "                 ======================================================\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the cleaned data\n",
    "df = pd.read_csv('cleaned_retail_data.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 1. Create Time-Based columns for analysis\n",
    "df['Month'] = df['Date'].dt.month_name()\n",
    "df['DayName'] = df['Date'].dt.day_name()\n",
    "\n",
    "# Set the visual style\n",
    "plt.style.use('fivethirtyeight')\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "\n",
    "# --- PLOT 1: Daily Sales Trend ---\n",
    "sns.lineplot(ax=axes[0, 0], data=df, x='Date', y='Sales', color='#30a2da')\n",
    "axes[0, 0].set_title('Daily Sales Volume (2014-2016)', fontsize=16)\n",
    "\n",
    "# --- PLOT 2: Sales by Day of the Week ---\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.barplot(ax=axes[0, 1], data=df, x='DayName', y='Sales', order=day_order, hue='DayName', palette='viridis', legend=False)\n",
    "axes[0, 1].set_title('Average Sales per Weekday', fontsize=16)\n",
    "\n",
    "# --- PLOT 3: Price vs. Sales (Correlation) ---\n",
    "sns.scatterplot(ax=axes[1, 0], data=df, x='Price', y='Sales', alpha=0.5, color='#fc4f30')\n",
    "axes[1, 0].set_title('Price Sensitivity (Sales vs. Price)', fontsize=16)\n",
    "\n",
    "# --- PLOT 4: Stock Levels Over Time ---\n",
    "sns.lineplot(ax=axes[1, 1], data=df, x='Date', y='Stock', color='#e5ae38')\n",
    "axes[1, 1].set_title('Inventory Levels (Stock on Hand)', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Print a quick Correlation Matrix\n",
    "print(\"--- Statistical Correlation ---\")\n",
    "print(df[['Sales', 'Price', 'Stock']].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3e3b8-4bff-45db-9378-ca18bc494cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466f088-f739-4e46-9379-710c018eee96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ea699-f4e9-4e30-83ee-01fea4bf8e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
